{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Please run the code blocks in order or click Run All.**",
   "id": "99dd24b76a18fd52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importing all the necessary libraries at start of the notebook to give a clean look.",
   "id": "c46efea4034742e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.293910Z",
     "start_time": "2025-05-28T11:17:12.982204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.customer_model import CustomerModel\n",
    "from models.transaction_model import TransactionModel\n",
    "from utils.arithmetic_helper import ArithmeticHelper\n",
    "from utils.constants import Constants\n",
    "from utils.csv_reader import CSVFileUtils\n",
    "import tabulate as tb\n",
    "from typing import Dict"
   ],
   "id": "b8cde03785362c2f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **0. Generate Dataset?**\n",
    "I have used a synthetic dataset which is generated from another three datasets. I have already generated the dataset and saved it in the 'data' folder. If you want to generate the dataset again, you can run the code block below. It will generate a new dataset in 'data' folder as 'transactions_generated.csv'. Please note that during each generation, the samples will be different as it is picked randomly from the original datasets. Please refresh the IDE's file browser to see the new generated file."
   ],
   "id": "853bdf678f43928e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.436803Z",
     "start_time": "2025-05-28T11:17:13.433305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from utils.synthetic_data_utils import SyntheticDataUtils\n",
    "# SyntheticDataUtils.generate_synthetic_data()"
   ],
   "id": "563b44d2ce1bb740",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **1. Hello Data!**\n",
    "To load any csv file, I have written a reusable class named CSVFileUtils which has methods to load and save csv files. While loading the csv file, you can specify the file path and the range of rows to load."
   ],
   "id": "fa285ba8be95ed9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.457643Z",
     "start_time": "2025-05-28T11:17:13.449070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_csv_data = CSVFileUtils.read_csv_with_rage(file_path=Constants.synth_generated_csv_file_path(),start=1,end=3)\n",
    "print(tb.tabulate(raw_csv_data,headers=\"keys\",tablefmt=\"outline\"))\n"
   ],
   "id": "8fc4b2f2a3e59dd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----------------------+---------------+----------------+-------------------+----------------+--------------+------------+---------+--------------------+-----------------+-----------------+\n",
      "|   order_id | order_date   |   days_since_purchase |   customer_id |   customer_age | customer_gender   | product_name   |   product_id |   quantity |   price |   discounted_price | coupon_code     | shipping_city   |\n",
      "+============+==============+=======================+===============+================+===================+================+==============+============+=========+====================+=================+=================+\n",
      "|  686800706 | 10/18/2014   |                     0 |          1647 |              0 | None              | T-shirt        |          131 |       8446 |      50 |                  0 | Hooray!! 342AHR | Nebraska        |\n",
      "|  185941302 | 11/7/2011    |                     0 |          1536 |              0 | None              | Dress          |          499 |       3018 |      93 |                  0 | Hooray!! 342AHR | West Virginia   |\n",
      "|  246222341 | 10/31/2016   |                     0 |          3256 |              0 | None              | Jeans          |          249 |       1517 |      41 |                  0 |                 | New Jersey      |\n",
      "+------------+--------------+-----------------------+---------------+----------------+-------------------+----------------+--------------+------------+---------+--------------------+-----------------+-----------------+\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## **2. Pick the Right Container**\n",
    "dict data-type is basically a key-value pair like a JSON object where a unique key is used to access its values. A named type, we can say it is a tuple with fixed field names and a class is a custom collection of data-types and methods."
   ],
   "id": "5651fd8fd374d92e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 3. Transaction Class and OO data structure\n",
    "I have created a `TransactionModel` class in `models/transaction_model.py`. This class contains a `from_raw_data` method which will generate a `TransactionModel` object from the raw data."
   ],
   "id": "73d96525bf6c69d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 4.\tBulk Loader\n",
    "\n",
    "TransactionModel class also contain a `load_transactions` method which will load the transactions from the raw data in the csv file. It will return a list of `TransactionModel` objects."
   ],
   "id": "9855d171ad6d8437"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.479859Z",
     "start_time": "2025-05-28T11:17:13.473478Z"
    }
   },
   "cell_type": "code",
   "source": "transactions_list:list[TransactionModel]  = TransactionModel.load_transactions()",
   "id": "4b582c8aadb048cf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 5. Quick Profiling\n",
    "I have created a 'ArithmeticHelper' class in 'utils/arithmetic_helper.py' which contains methods to do basic mean, min, max, count operations."
   ],
   "id": "f2f0f6f6b1200295"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.539618Z",
     "start_time": "2025-05-28T11:17:13.533549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prices = [t.price for t in transactions_list]\n",
    "cities = [t.shipping_city for t in transactions_list]\n",
    "print(\"Min (price): \", ArithmeticHelper.calculate_min(prices))\n",
    "print(\"Mean (price): \", ArithmeticHelper.calculate_mean(prices))\n",
    "print(\"Max (price): \", ArithmeticHelper.calculate_max(prices))\n",
    "print(\"Unique count (city): \", ArithmeticHelper.unique_items_count(cities))\n"
   ],
   "id": "259417b4feb426c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min (price):  10.0\n",
      "Mean (price):  56.885\n",
      "Max (price):  100.0\n",
      "Unique count (city):  50\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 6. Spot the Grime\n",
    "1. The dates in the dataset are in different formats.\n",
    "2. The Price field have values which are not numbers or non parsable numbers.\n",
    "3. Product name string is not standardized. Can be trimmed and converted to title case, can remove double spaces and special characters.\n",
    "4. Shipping city names are not standardized. Can be trimmed and converted to title case, can remove double spaces and special characters.\n"
   ],
   "id": "d087030cf0ed3eea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 7. Cleaning Rules\n",
    "The `TransactionModel` class has a `clean` method which will clean the transaction data. It will remove the leading and trailing spaces, convert the strings to title case, remove double spaces and special characters from the product name and shipping city name. It will also convert the date to a standard format and parse the price to a float value."
   ],
   "id": "ac60291ef0cb2114"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.576157Z",
     "start_time": "2025-05-28T11:17:13.559829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned_transactions_list :list[TransactionModel]= []\n",
    "\n",
    "for t in transactions_list:\n",
    "    cleaned_object = t.clean()\n",
    "    if cleaned_object is not None:\n",
    "        cleaned_transactions_list.append(cleaned_object)\n",
    "\n",
    "print(\"Raw transaction list length\", len(transactions_list))\n",
    "print(\"Clean transaction list length\", len(cleaned_transactions_list))\n",
    "if len(cleaned_transactions_list) == len(transactions_list):\n",
    "    print(\"Hooray!! All transactions are cleaned successfully.\")\n",
    "else:\n",
    "    print(\"Some transactions are not cleaned successfully.\")\n"
   ],
   "id": "419ee6785f76c7a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw transaction list length 1000\n",
      "Clean transaction list length 1000\n",
      "Hooray!! All transactions are cleaned successfully.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 8. Transformations\n",
    "\n",
    "The `TransactionModel` class has a `calculate_discount` method which will calculate the discount if there is coupon code present in the transaction object."
   ],
   "id": "987b7356220d87fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.590681Z",
     "start_time": "2025-05-28T11:17:13.587431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for t in cleaned_transactions_list:\n",
    "    t.calculate_discount()"
   ],
   "id": "10f5c1c9cb2fa3d8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 9. Feature Engineering\n",
    "\n",
    "The `TransactionModel` class has a `calculate_days_since_purchase` method which will calculate the days since the purchase was made.\n"
   ],
   "id": "f83d523e49c882c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.637501Z",
     "start_time": "2025-05-28T11:17:13.610542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for t in cleaned_transactions_list:\n",
    "    t.calculate_days_since_purchase()"
   ],
   "id": "71adbae870e68c06",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## \t10. Mini-Aggregation\n",
    "The `ArithmeticHelper` class has `calculate_revenue_per_shipping_city` method to calculate revenue by shipping city which also takes discounts into considerations.\n"
   ],
   "id": "b0dc2b28cc14fff9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.661644Z",
     "start_time": "2025-05-28T11:17:13.656526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "city_and_revenue:Dict[str, float] = ArithmeticHelper.calculate_revenue_per_shipping_city(cleaned_transactions_list)\n",
    "for i in range(3):\n",
    "    print(f\"City: {list(city_and_revenue.keys())[i]}, Revenue: {list(city_and_revenue.values())[i]}\")\n"
   ],
   "id": "c08f0dd70714b218",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: Nebraska, Revenue: 6765010.600000001\n",
      "City: West Virginia, Revenue: 5846367.399999999\n",
      "City: New Jersey, Revenue: 5265584.800000001\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 11. Serialization Checkpoint\n",
    "\n",
    "The `TransactionModel` class has a `to_dict` method which will convert the transaction object to a JSON string. The class also have a `save_transactions_to_json_file` method which will take a list of transaction objects and save them to a JSON file. The `TransactionModel` class also has a `save_transactions_to_parquet` method which will save the transactions to a parquet file.\n",
    "The files will be saved in the 'data/cleaned' folder'.\n"
   ],
   "id": "65efaba6cf93e553"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.735573Z",
     "start_time": "2025-05-28T11:17:13.680087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TransactionModel.save_transactions_to_json_file(cleaned_transactions_list)\n",
    "TransactionModel.save_transactions_to_parquet(cleaned_transactions_list)"
   ],
   "id": "43b417281797705c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 12. Soft Interview Reflection\n",
    "The OOPs have helped me to create a clean and reusable code structure. I have used the TransactionModel class to encapsulate the transaction data and its methods. The CSVFileUtils class has helped me to load and save the csv files in a reusable way. The ArithmeticHelper class has helped me to do basic arithmetic operations on the transaction data. Overall, I feel that my code is readable, maintainable and reusable and makes more sense to anyone who is reading it."
   ],
   "id": "7c5ac3152c7294cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 13. Data-Dictionary Section\n",
    "I am merging customers gender and age from customer dataset to the transactions dataset."
   ],
   "id": "43fcb33b9c00f084"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:13.992491Z",
     "start_time": "2025-05-28T11:17:13.748417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "customer_raw_data = CSVFileUtils.read_csv_with_rage(file_path=Constants.customer_csv_file_path(),start=1)\n",
    "customer_list: list[CustomerModel] = []\n",
    "for row in customer_raw_data:\n",
    "    customer_list.append(CustomerModel.from_raw_data(row))\n",
    "\n",
    "for t in cleaned_transactions_list:\n",
    "    for c in customer_list:\n",
    "        if t.customer_id == c.customer_id:\n",
    "            t.add_customer_info(c)\n",
    "\n",
    "new_table = tb.tabulate([txn.to_dict() for txn in cleaned_transactions_list[:3]],headers=\"keys\",tablefmt=\"outline\")\n",
    "print(new_table)"
   ],
   "id": "6596d6cf8c9b29bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----------------------+---------------+----------------+-------------------+----------------+--------------+------------+---------+--------------------+-----------------+-----------------+\n",
      "|   order_id | order_date   |   days_since_purchase |   customer_id |   customer_age | customer_gender   | product_name   |   product_id |   quantity |   price |   discounted_price | coupon_code     | shipping_city   |\n",
      "+============+==============+=======================+===============+================+===================+================+==============+============+=========+====================+=================+=================+\n",
      "|  686800706 | 2014-10-18   |                  3875 |          1647 |             58 | Male              | Tshirt         |          131 |       8446 |      50 |               45   | Hooray!! 342AHR | Nebraska        |\n",
      "|  185941302 | 2011-11-07   |                  4951 |          1536 |             36 | Male              | Dress          |          499 |       3018 |      93 |               83.7 | Hooray!! 342AHR | West Virginia   |\n",
      "|  246222341 | 2016-10-31   |                  3131 |          3256 |             57 | Female            | Jeans          |          249 |       1517 |      41 |               41   |                 | New Jersey      |\n",
      "+------------+--------------+-----------------------+---------------+----------------+-------------------+----------------+--------------+------------+---------+--------------------+-----------------+-----------------+\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Dictionary for the final dataset is as follows:\n",
    "\n",
    "| Field               | Type | Description                                | Source                                   |\n",
    "|---------------------|------|--------------------------------------------|------------------------------------------|\n",
    "| order_id            | int  | Unique Id for an order                     | transactions_generated.csv               |\n",
    "| order_date          | date | Date in which order was placed             | transactions_generated.csv               |\n",
    "| days_since_purchase | int  | Days till today from order_date            | transactions_generated.csv - calculated  |\n",
    "| customer_id         | int  | Unique Id for a customer                   | customer.csv                             |\n",
    "| customer_age        | int  | Age of customer                            | customer.csv                             |\n",
    "| customer_gender     | enum | Gender of customer                         | customer.csv                             |\n",
    "| product_name        | str  | Name of product                            | fashion_product.csv                      |\n",
    "| product_id          | int  | Unique Id for a product                    | fashion_product.csv                      |\n",
    "| quantity            | int  | Quantity of product in order               | transactions_generated.csv               |\n",
    "| price               | int  | Price of product                           | transactions_generated.csv               |\n",
    "| discounted_price    | int  | Price after reducing coupon offer          | transactions_generated.csv  - calculated |\n",
    "| coupon_code         | str  | A discount code                            | transactions_generated.csv               |\n",
    "| shipping_city       | str  | Address to which the order is being placed | customer.csv                             |\n"
   ],
   "id": "5aa74f507be1a497"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References:\n",
    "- [E-commerce dataset](https://excelbianalytics.com/wp/wp-content/uploads/2017/07/1000-Sales-Records.zip)\n",
    "- [Customer datasets](https://www.kaggle.com/datasets/bhadramohit/customer-shopping-latest-trends-dataset)\n",
    "- [Products dataset](https://www.kaggle.com/datasets/bhanupratapbiswas/fashion-products)\n",
    "- [Python OOPs Concepts](https://www.geeksforgeeks.org/python-oops-concepts/)\n",
    "- [Python CSV File Handling](https://docs.python.org/3/library/csv.html#module-csv)\n",
    "- [Parquet](https://pypi.org/project/parquet/)"
   ],
   "id": "cd6bf4116ae5698f"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
